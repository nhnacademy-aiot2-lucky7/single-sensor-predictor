import logging
import os
import json
from datetime import datetime

from src.sensor_predictor.influx_service import InfluxService
from src.sensor_predictor.predictor_service import PredictorService
from src.sensor_predictor.sensor_api import load_sensor_list
from src.storage.local_storage import LocalStorage
from dotenv import load_dotenv

logging.basicConfig(level=logging.INFO)

load_dotenv()

INFLUXDB_URL = os.getenv("INFLUXDB_URL")
INFLUXDB_TOKEN = os.getenv("INFLUXDB_TOKEN")
INFLUXDB_ORG = os.getenv("INFLUXDB_ORG")
INFLUXDB_BUCKET = os.getenv("INFLUXDB_BUCKET")
DURATION = os.getenv("DURATION", "-7d")
PREDICT_DAYS = int(os.getenv("PREDICT_DAYS", 1))

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
influx = InfluxService(INFLUXDB_URL, INFLUXDB_TOKEN, INFLUXDB_ORG, INFLUXDB_BUCKET)
predictor = PredictorService()
storage = LocalStorage()

SENSOR_ID = "sensor-id"
GATEWAY_ID = "gateway-id"
SENSOR_TYPE = "sensor_type"

def run_prediction_service(predict_days: int):
    logging.info("ğŸ“¡ [1/3] completed ì„¼ì„œ ëª©ë¡ ì¡°íšŒ ì¤‘...")

    completed_sensors = load_sensor_list()

    logging.info(f"[ì„¼ì„œ ê°œìˆ˜] {len(completed_sensors)}ê°œ")
    logging.info("ğŸ“¡ [2/3] ì„¼ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì¤‘...")

    sensor_meta = influx.get_sensor_metadata(DURATION, completed_sensors)

    logging.info(f"ì„¼ì„œ ë©”íƒ€ë°ì´í„° ê°œìˆ˜: {len(sensor_meta)}")
    if not sensor_meta:
        logging.warning("ì„¼ì„œ ë©”íƒ€ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! ì˜ˆì¸¡ ë¶ˆê°€.")
        return

    logging.info("ğŸ”® [3/3] ì„¼ì„œ ì˜ˆì¸¡ ì‹œì‘...")
    for sensor in sensor_meta:
        raw_data = influx.load_sensor_data(
            sensor[SENSOR_ID],
            sensor[GATEWAY_ID],
            sensor[SENSOR_TYPE],
            DURATION
        )

        if not raw_data:
            logging.warning(f"âš ï¸ í•™ìŠµ ë°ì´í„° ì—†ìŒ - sensor-id={sensor[SENSOR_ID]}, gateway_id={sensor[GATEWAY_ID]}")
            continue

        logging.info("ì—¬ê¸°ê¹Œì§€ ì¶œë ¥ !!!")

        result = predictor.run_forecast(
            sensor[GATEWAY_ID],
            sensor[SENSOR_ID],
            sensor[SENSOR_TYPE],
            raw_data,
            predict_days=predict_days
        )

        if result:
            logging.info("ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼:")
            print(json.dumps(result, indent=2))

            model = predictor.get_trained_model(
                sensor[GATEWAY_ID],
                sensor[SENSOR_ID],
                sensor[SENSOR_TYPE],
            )
            if model:
                base_date = datetime.now()
                storage.save_model(model, sensor[SENSOR_ID], sensor[SENSOR_TYPE], base_date)
                logging.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: sensor-id={sensor[SENSOR_ID]} ë‚ ì§œ={base_date.isoformat()}")
        else:
            logging.warning(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ: sensor-id={sensor[SENSOR_ID]}")

    logging.info("âœ… ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì™„ë£Œ")

def run_job(predict_days: int):
    try:
        logging.info("ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì‹œì‘")
        run_prediction_service(predict_days)
        logging.info("ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)

if __name__ == "__main__":
    default_predict_days = int(os.getenv("PREDICT_DAYS", PREDICT_DAYS))
    run_job(default_predict_days)
